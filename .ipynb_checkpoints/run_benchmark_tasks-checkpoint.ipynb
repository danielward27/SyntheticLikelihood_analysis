{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this script needs a conda environment with sbibm installed, e.g.:\n",
    "\n",
    "# using Conda\n",
    "# using Pkg\n",
    "\n",
    "# ENV[\"PYTHON\"] = \"\"\n",
    "# Pkg.build(\"PyCall\")\n",
    "\n",
    "# Conda.pip_interop(true)\n",
    "# Conda.pip(\"install\", \"sbibm\")\n",
    "\n",
    "# Make sure up to date\n",
    "# Pkg.rm(\"SyntheticLikelihood\")\n",
    "# Pkg.add(url=\"https://github.com/danielward27/SyntheticLikelihood.jl\")\n",
    "using SyntheticLikelihood\n",
    "using PyCall\n",
    "using Distributions\n",
    "using DelimitedFiles\n",
    "using Random\n",
    "using Parameters\n",
    "using LinearAlgebra\n",
    "using DataFrames\n",
    "using CSV\n",
    "\n",
    "sbibm = pyimport(\"sbibm\")\n",
    "torch = pyimport(\"torch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert stuff from python to julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"gaussian_linear\", \"gaussian_linear_uniform\", \"gaussian_mixture\", \"sir\", \"bernoulli_glm\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_priors = include(\"task_priors.jl\")\n",
    "String.(keys(task_priors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough test that prior conversion looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in String.(keys(task_priors))\n",
    "    n = 2000\n",
    "    jl_prior = task_priors[Symbol(task_name)]\n",
    "    jl_samples = sample_θ(jl_prior, n)\n",
    "    jl_mean = mean.(eachcol(jl_samples))\n",
    "    jl_cov = cov(jl_samples)\n",
    "\n",
    "    py_prior = sbibm.get_task(task_name).get_prior()\n",
    "    py_samples = py_prior(n).numpy();\n",
    "    py_mean = mean.(eachcol(py_samples))\n",
    "    py_cov = cov(py_samples)\n",
    "    \n",
    "    println(task_name)\n",
    "    println(\"Julia means = $(round.(jl_mean; digits = 2))\")\n",
    "    println(\"Python means = $(round.(py_mean; digits = 2)) \\n\")\n",
    "    \n",
    "    @assert size(py_mean) == size(jl_mean)\n",
    "    @assert isapprox(py_mean, jl_mean; rtol = 2)\n",
    "    @assert isapprox(py_cov, jl_cov; rtol = 0.7)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the variance ratios between prior and posterior\n",
    "To get a good idea for the defualt proposal we can compare the variance of the posterior to the prior on the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_linear: 0.4998179227113724\n",
      "gaussian_linear_uniform: 0.2024229694157839\n",
      "gaussian_mixture: 0.010489855706691741\n",
      "sir: 0.1139117874962996\n",
      "bernoulli_glm: 0.0981549893539872\n",
      "The mean variance ratio is 0.18495950493682695\n"
     ]
    }
   ],
   "source": [
    "mean_ratio = begin\n",
    "    ratios = []\n",
    "    for task_name in String.(keys(task_priors))\n",
    "        n = 2000\n",
    "        jl_prior = task_priors[Symbol(task_name)]\n",
    "        prior_var = diag(cov(jl_prior))\n",
    "        py_task = sbibm.get_task(task_name)\n",
    "        posterior_samples = py_task.get_reference_posterior_samples(1).numpy()\n",
    "        posterior_var = diag(cov(posterior_samples))\n",
    "        ratio = mean(posterior_var ./ prior_var)\n",
    "        println(task_name, \": \", ratio)\n",
    "        push!(ratios, ratio)\n",
    "    end\n",
    "    mean(ratios)\n",
    "end\n",
    "\n",
    "println(\"The mean variance ratio is $(mean_ratio)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_jl_simulator(task)   \n",
    "    py_simulator = task.get_simulator()\n",
    "    simulator(θ::Vector{Float64}) = begin\n",
    "        θ = torch.tensor(θ, dtype = torch.float32)\n",
    "        x = py_simulator(θ)\n",
    "        convert(Vector{Float64}, vec(x.numpy()))\n",
    "    end\n",
    "    simulator\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct JuliaTask\n",
    "    name\n",
    "    simulator\n",
    "    prior\n",
    "    s_true\n",
    "    obs_seed\n",
    "end\n",
    "\n",
    "function JuliaTask(python_task, obs_seed::Integer)\n",
    "    name = python_task.name\n",
    "    simulator = get_jl_simulator(python_task)\n",
    "    prior = task_priors[Symbol(name)]\n",
    "    s_true = vec(python_task.get_observation(obs_seed).numpy())\n",
    "    s_true = convert(Vector{Float64}, s_true)\n",
    "    JuliaTask(name, simulator, prior, s_true, obs_seed)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get starting parameters\n",
    "To get the starting parameters I will sample 1000 sets of parameters and take the mean of all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_starting_params (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_starting_params(prior::Prior)\n",
    "    mean.(eachcol(sample_θ(prior, 1000)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through tasks and run the Riemannian ULA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "const n_steps = 4000\n",
    "const n_sim = 1000  # at each mcmc iteration\n",
    "const n_burn = 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"rula\"\n",
    "tasks = []\n",
    "run_times = []\n",
    "\n",
    "for (i, task_name) in enumerate(String.(keys(task_priors)))\n",
    "    @info \"Task = $(task_name)\"\n",
    "\n",
    "    Random.seed!(i)\n",
    "    pytask = sbibm.get_task(task_name)\n",
    "    jltask = JuliaTask(pytask, 1)\n",
    "    @unpack simulator, prior, s_true, obs_seed = jltask\n",
    "    \n",
    "    init_θ = get_starting_params(prior)\n",
    "\n",
    "    local_posterior = LocalPosterior(;\n",
    "      simulator, s_true, n_sim, prior,\n",
    "    )\n",
    "    \n",
    "    rula = RiemannianULA(0.2)\n",
    "    \n",
    "    time = @elapsed data = run_sampler!(rula, local_posterior; init_θ, n_steps)\n",
    "    open(\"./samples/$(task_name)_$(algorithm).txt\", \"w\") do io\n",
    "        writedlm(io, data.θ[(n_burn+1):end, :])\n",
    "    end\n",
    "                             \n",
    "    push!(tasks, task_name)\n",
    "    push!(run_times, time)\n",
    "\n",
    "end\n",
    "\n",
    "df = DataFrame(task = tasks, run_time = run_times)\n",
    "CSV.write(\"./results/$(algorithm).csv\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through tasks and run basic Bayesian Synthetic Likelihood\n",
    "Below we use standard synthetic likelihood. We use a burn in of 1000 steps (either accepted or rejected), and then use the empirical covariance matrix of the last 75% of samples of the burn in to form the proposal distribution for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Task = gaussian_linear\n",
      "└ @ Main In[34]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:36\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:16:10\u001b[39m\n",
      "┌ Info: Task = gaussian_linear_uniform\n",
      "└ @ Main In[34]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:43\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:16:37\u001b[39m\n",
      "┌ Info: Task = gaussian_mixture\n",
      "└ @ Main In[34]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:18\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:10:27\u001b[39m\n",
      "┌ Info: Task = sir\n",
      "└ @ Main In[34]:8\n",
      "\u001b[32mProgress:  15%|██████                                   |  ETA: 0:32:06\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] sigatomic_end",
      "    @ ./c.jl:437 [inlined]",
      "  [2] disable_sigint",
      "    @ ./c.jl:460 [inlined]",
      "  [3] __pycall!",
      "    @ ~/.julia/packages/PyCall/tqyST/src/pyfncall.jl:42 [inlined]",
      "  [4] _pycall!(ret::PyObject, o::PyObject, args::Tuple{PyObject}, nargs::Int64, kw::Ptr{Nothing})",
      "    @ PyCall ~/.julia/packages/PyCall/tqyST/src/pyfncall.jl:29",
      "  [5] _pycall!",
      "    @ ~/.julia/packages/PyCall/tqyST/src/pyfncall.jl:11 [inlined]",
      "  [6] #_#116",
      "    @ ~/.julia/packages/PyCall/tqyST/src/pyfncall.jl:86 [inlined]",
      "  [7] (::PyObject)(args::PyObject)",
      "    @ PyCall ~/.julia/packages/PyCall/tqyST/src/pyfncall.jl:86",
      "  [8] (::var\"#simulator#10\"{PyObject})(θ::Vector{Float64})",
      "    @ Main ./In[11]:5",
      "  [9] simulate_n_s(θ::Vector{Float64}; simulator::var\"#simulator#10\"{PyObject}, summary::typeof(identity), n_sim::Int64, parallel::Bool)",
      "    @ SyntheticLikelihood ~/.julia/packages/SyntheticLikelihood/vVDAq/src/simulate_n_s.jl:39",
      " [10] obj_grad_hess(basic_posterior::BasicPosterior, θ::Vector{Float64})",
      "    @ SyntheticLikelihood ~/.julia/packages/SyntheticLikelihood/vVDAq/src/local_regression.jl:120",
      " [11] update!(sampler::RWMetropolis, local_approximation::BasicPosterior, state::SyntheticLikelihood.RWMetropolisState)",
      "    @ SyntheticLikelihood ~/.julia/packages/SyntheticLikelihood/vVDAq/src/samplers.jl:194",
      " [12] macro expansion",
      "    @ ~/.julia/packages/SyntheticLikelihood/vVDAq/src/samplers.jl:134 [inlined]",
      " [13] macro expansion",
      "    @ ~/.julia/packages/ProgressMeter/0ub8y/src/ProgressMeter.jl:773 [inlined]",
      " [14] run_sampler!(sampler::RWMetropolis, local_approximation::BasicPosterior; init_θ::Vector{Float64}, n_steps::Int64, collect_data::Vector{Symbol}, progress::Bool)",
      "    @ SyntheticLikelihood ~/.julia/packages/SyntheticLikelihood/vVDAq/src/samplers.jl:132",
      " [15] macro expansion",
      "    @ timing.jl:287 [inlined]",
      " [16] top-level scope",
      "    @ In[34]:22",
      " [17] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [18] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "algorithm = \"bsl\"\n",
    "tasks = []\n",
    "run_times = []\n",
    "accecptance_rates = []\n",
    "\n",
    "\n",
    "for (i, task_name) in enumerate(String.(keys(task_priors)))\n",
    "    @info \"Task = $(task_name)\"\n",
    "\n",
    "    Random.seed!(i)\n",
    "    pytask = sbibm.get_task(task_name)\n",
    "    jltask = JuliaTask(pytask, 1)\n",
    "    \n",
    "    @unpack simulator, prior, s_true, obs_seed = jltask\n",
    "    \n",
    "    init_θ = get_starting_params(prior)\n",
    "    \n",
    "    # Burn in 1000 \"steps\" and 0.3*covariance of the prior\n",
    "    rwm = RWMetropolis(MvNormal(0.2*cov(prior)))\n",
    "    basic_posterior = BasicPosterior(;simulator, s_true, n_sim, prior)\n",
    "    \n",
    "    time1 = @elapsed data = run_sampler!(rwm, basic_posterior; init_θ, n_steps = n_burn, collect_data = [:θ, :accepted])\n",
    "\n",
    "    \n",
    "    burn_in_θ = data.θ\n",
    "    quarter = round(Int64, size(burn_in_θ, 1)*0.25)  \n",
    "    new_Σ = cov(burn_in_θ[quarter:end, :])\n",
    "    init_θ = burn_in_θ[end, :]\n",
    "        \n",
    "    # Actual run\n",
    "    rwm = RWMetropolis(MvNormal(new_Σ))\n",
    "    basic_posterior = BasicPosterior(;simulator, s_true, n_sim, prior)\n",
    "    time2 = @elapsed data = run_sampler!(rwm, basic_posterior; init_θ, n_steps = n_steps - n_burn, collect_data = [:θ, :accepted])\n",
    "     \n",
    "    open(\"./samples/$(task_name)_$(algorithm).txt\", \"w\") do io\n",
    "            writedlm(io, data.θ)\n",
    "    end\n",
    "    \n",
    "    push!(tasks, task_name)\n",
    "    push!(run_times, time1 + time2)\n",
    "    push!(accecptance_rates, sum(data.accepted)/length(data.accepted))\n",
    "end\n",
    "\n",
    "df = DataFrame(task = tasks, run_time = run_times, acceptance_rate = accecptance_rates)\n",
    "CSV.write(\"./results/$(algorithm).csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using DelimitedFiles\n",
    "#using GLM\n",
    "#X = readdlm(\"X.txt\")\n",
    "#y = readdlm(\"y.txt\")\n",
    "#y = reshape(y, length(y))\n",
    "#glm(X, y, Gamma(), LogLink(), maxiter=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
