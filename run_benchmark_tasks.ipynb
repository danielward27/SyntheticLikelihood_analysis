{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this script needs a conda environment with sbibm installed, e.g.:\n",
    "\n",
    "# using Conda\n",
    "# using Pkg\n",
    "\n",
    "# ENV[\"PYTHON\"] = \"\"\n",
    "# Pkg.build(\"PyCall\")\n",
    "\n",
    "# Conda.pip_interop(true)\n",
    "# Conda.pip(\"install\", \"sbibm\")\n",
    "\n",
    "# Make sure up to date\n",
    "# Pkg.rm(\"SyntheticLikelihood\")\n",
    "# Pkg.add(url=\"https://github.com/danielward27/SyntheticLikelihood.jl\")\n",
    "using SyntheticLikelihood\n",
    "using PyCall\n",
    "using Distributions\n",
    "using DelimitedFiles\n",
    "using Random\n",
    "using Parameters\n",
    "using LinearAlgebra\n",
    "using DataFrames\n",
    "using CSV\n",
    "\n",
    "sbibm = pyimport(\"sbibm\")\n",
    "torch = pyimport(\"torch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert stuff from python to julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"gaussian_linear\", \"gaussian_linear_uniform\", \"gaussian_mixture\", \"sir\", \"bernoulli_glm\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_priors = include(\"task_priors.jl\")\n",
    "String.(keys(task_priors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough test that prior conversion looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in String.(keys(task_priors))\n",
    "    n = 2000\n",
    "    jl_prior = task_priors[Symbol(task_name)]\n",
    "    jl_samples = sample_θ(jl_prior, n)\n",
    "    jl_mean = mean.(eachcol(jl_samples))\n",
    "    jl_cov = cov(jl_samples)\n",
    "\n",
    "    py_prior = sbibm.get_task(task_name).get_prior()\n",
    "    py_samples = py_prior(n).numpy();\n",
    "    py_mean = mean.(eachcol(py_samples))\n",
    "    py_cov = cov(py_samples)\n",
    "    \n",
    "    println(task_name)\n",
    "    println(\"Julia means = $(round.(jl_mean; digits = 2))\")\n",
    "    println(\"Python means = $(round.(py_mean; digits = 2)) \\n\")\n",
    "    \n",
    "    @assert size(py_mean) == size(jl_mean)\n",
    "    @assert isapprox(py_mean, jl_mean; rtol = 2)\n",
    "    @assert isapprox(py_cov, jl_cov; rtol = 0.7)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the variance ratios between prior and posterior\n",
    "To get a good idea for the defualt proposal we can compare the variance of the posterior to the prior on the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratio = begin\n",
    "    ratios = []\n",
    "    for task_name in String.(keys(task_priors))\n",
    "        n = 2000\n",
    "        jl_prior = task_priors[Symbol(task_name)]\n",
    "        prior_var = diag(cov(jl_prior))\n",
    "        py_task = sbibm.get_task(task_name)\n",
    "        posterior_samples = py_task.get_reference_posterior_samples(1).numpy()\n",
    "        posterior_var = diag(cov(posterior_samples))\n",
    "        ratio = mean(posterior_var ./ prior_var)\n",
    "        println(task_name, \": \", ratio)\n",
    "        push!(ratios, ratio)\n",
    "    end\n",
    "    mean(ratios)\n",
    "end\n",
    "\n",
    "println(\"The mean variance ratio is $(mean_ratio)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_jl_simulator(task)   \n",
    "    py_simulator = task.get_simulator()\n",
    "    simulator(θ::Vector{Float64}) = begin\n",
    "        θ = torch.tensor(θ, dtype = torch.float32)\n",
    "        x = py_simulator(θ)\n",
    "        convert(Vector{Float64}, vec(x.numpy()))\n",
    "    end\n",
    "    simulator\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct JuliaTask\n",
    "    name\n",
    "    simulator\n",
    "    prior\n",
    "    s_true\n",
    "    obs_seed\n",
    "end\n",
    "\n",
    "function JuliaTask(python_task, obs_seed::Integer)\n",
    "    name = python_task.name\n",
    "    simulator = get_jl_simulator(python_task)\n",
    "    prior = task_priors[Symbol(name)]\n",
    "    s_true = vec(python_task.get_observation(obs_seed).numpy())\n",
    "    s_true = convert(Vector{Float64}, s_true)\n",
    "    JuliaTask(name, simulator, prior, s_true, obs_seed)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through tasks and run the Riemannian ULA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const n_steps = 4000\n",
    "const n_sim = 1000  # at each mcmc iteration\n",
    "const n_burn = 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"rula\"\n",
    "tasks = []\n",
    "run_times = []\n",
    "\n",
    "for (i, task_name) in enumerate(String.(keys(task_priors)))\n",
    "    @info \"Task = $(task_name)\"\n",
    "\n",
    "    Random.seed!(i)\n",
    "    pytask = sbibm.get_task(task_name)\n",
    "    jltask = JuliaTask(pytask, 1)\n",
    "    \n",
    "    @unpack simulator, prior, s_true, obs_seed = jltask\n",
    "    \n",
    "    init_θ = sample_θ(prior)\n",
    "\n",
    "    local_posterior = LocalPosterior(;\n",
    "      simulator, s_true, n_sim, prior,\n",
    "    )\n",
    "    \n",
    "    rula = RiemannianULA(0.2)\n",
    "    \n",
    "    time = @elapsed data = run_sampler!(rula, local_posterior; init_θ, n_steps)\n",
    "    open(\"./samples/$(task_name)_$(algorithm).txt\", \"w\") do io\n",
    "        writedlm(io, data.θ[(n_burn+1):end, :])\n",
    "    end\n",
    "                             \n",
    "    push!(tasks, task_name)\n",
    "    push!(run_times, time)\n",
    "\n",
    "end\n",
    "\n",
    "df = DataFrame(task = tasks, run_time = run_times)\n",
    "CSV.write(\"./results/$(algorithm).csv\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through tasks and run basic Bayesian Synthetic Likelihood\n",
    "Below we use standard synthetic likelihood. We use a burn in of 1000 \"steps\" (either accepted or rejected), and then use the empirical covariance matrix of the last 75% of samples of the burn in to form the proposal distribution for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Task = gaussian_linear\n",
      "└ @ Main In[6]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:57\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:14:02\u001b[39m\n",
      "┌ Info: Task = gaussian_linear_uniform\n",
      "└ @ Main In[6]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:38\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:13:52\u001b[39m\n",
      "┌ Info: Task = gaussian_mixture\n",
      "└ @ Main In[6]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:44\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:08:25\u001b[39m\n",
      "┌ Info: Task = sir\n",
      "└ @ Main In[6]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:37:03\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 1:58:52\u001b[39m\n",
      "┌ Info: Task = bernoulli_glm\n",
      "└ @ Main In[6]:8\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:11\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:14:57\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"./results/bsl.csv\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm = \"bsl\"\n",
    "tasks = []\n",
    "run_times = []\n",
    "accecptance_rates = []\n",
    "\n",
    "\n",
    "for (i, task_name) in enumerate(String.(keys(task_priors)))\n",
    "    @info \"Task = $(task_name)\"\n",
    "\n",
    "    Random.seed!(i)\n",
    "    pytask = sbibm.get_task(task_name)\n",
    "    jltask = JuliaTask(pytask, 1)\n",
    "    \n",
    "    @unpack simulator, prior, s_true, obs_seed = jltask\n",
    "    \n",
    "    init_θ = sample_θ(prior)\n",
    "    \n",
    "    # Burn in 1000 \"steps\" and 0.2*covariance of the prior\n",
    "    rwm = RWMetropolis(MvNormal(0.2*cov(prior)))\n",
    "    basic_posterior = BasicPosterior(;simulator, s_true, n_sim, prior)\n",
    "    \n",
    "    time1 = @elapsed data = run_sampler!(rwm, basic_posterior; init_θ, n_steps = n_burn, collect_data = [:θ, :accepted])\n",
    "\n",
    "    \n",
    "    burn_in_θ = data.θ[data.accepted, :]\n",
    "    quarter = round(Int64, size(burn_in_θ, 1)*0.25)  \n",
    "    new_Σ = cov(burn_in_θ[quarter:end, :])\n",
    "        \n",
    "    # Actual run\n",
    "    rwm = RWMetropolis(MvNormal(new_Σ))\n",
    "    basic_posterior = BasicPosterior(;simulator, s_true, n_sim, prior)\n",
    "    time2 = @elapsed data = run_sampler!(rwm, basic_posterior; init_θ, n_steps = n_steps - n_burn, collect_data = [:θ, :accepted])\n",
    "     \n",
    "    open(\"./samples/$(task_name)_$(algorithm).txt\", \"w\") do io\n",
    "            writedlm(io, data.θ[data.accepted, :])\n",
    "    end\n",
    "    \n",
    "    push!(tasks, task_name)\n",
    "    push!(run_times, time1 + time2)\n",
    "    push!(accecptance_rates, sum(data.accepted)/length(data.accepted))\n",
    "end\n",
    "\n",
    "df = DataFrame(task = tasks, run_time = run_times, acceptance_rate = accecptance_rates)\n",
    "CSV.write(\"./results/$(algorithm).csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using DelimitedFiles\n",
    "#using GLM\n",
    "#X = readdlm(\"X.txt\")\n",
    "#y = readdlm(\"y.txt\")\n",
    "#y = reshape(y, length(y))\n",
    "#glm(X, y, Gamma(), LogLink(), maxiter=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
