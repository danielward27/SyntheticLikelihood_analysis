{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad2cc8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b9d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sbibm\n",
    "import torch\n",
    "import altair_saver\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from sbibm.metrics import c2st\n",
    "from sbibm.visualisation import fig_posterior\n",
    "from sbibm.metrics import c2st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb616e0",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911a3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin(X, length_out):\n",
    "    assert length_out < X.shape[0]\n",
    "    n = X.shape[0]\n",
    "    keep = np.round(np.linspace(1, n, num = length_out)) - 1\n",
    "    keep = keep.astype(int)\n",
    "    return X[keep, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbfd943",
   "metadata": {},
   "source": [
    "## Posterior plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c63c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dw16200/miniconda3/envs/sbi_env/lib/python3.9/site-packages/diffeqtorch/diffeqtorch.py:29: UserWarning: JULIA_SYSIMAGE_DIFFEQTORCH not set\n",
      "  warn(\"JULIA_SYSIMAGE_DIFFEQTORCH not set\")\n"
     ]
    }
   ],
   "source": [
    "task_names = [\"gaussian_linear\", \"gaussian_linear_uniform\", \"gaussian_mixture\", \"sir\", \"bernoulli_glm\"]\n",
    "algorithm_names = [\"rula\", \"bsl\"]\n",
    "\n",
    "plot_n = 1000\n",
    "for task_name in task_names:\n",
    "    for algorithm_name in algorithm_names:\n",
    "        posterior_samples = np.genfromtxt(f\"./samples/{task_name}_{algorithm_name}.txt\")\n",
    "        posterior_samples = thin(posterior_samples, plot_n)\n",
    "        posterior_samples = torch.tensor(posterior_samples)        \n",
    "        \n",
    "        n_params = posterior_samples.shape[1] \n",
    "        fig_size = 400-35*n_params\n",
    "        scatter_size = 3.5+0.05*n_params\n",
    "\n",
    "        fig = fig_posterior(\n",
    "            task_name=task_name,\n",
    "            observation=1,\n",
    "            samples_tensor = posterior_samples,\n",
    "            num_samples = plot_n,\n",
    "            config = \"streamlit\",\n",
    "            height = fig_size,\n",
    "            width = fig_size,\n",
    "            scatter_size = scatter_size,\n",
    "            samples_name = algorithm_name\n",
    "        )\n",
    "        altair_saver.save(fig, f\"./plots/{task_name}_{algorithm_name}.html\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3dde2",
   "metadata": {},
   "source": [
    "## Performance metrics\n",
    "We will compute the classification accuracy twice. Once on all the samples (3000), then once on a thinned sample of 300 points. The size of the reference is matched to the size of the data to make sure the neural network did not have issues with the biased class sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeab765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian_linear: rula\n",
      "gaussian_linear: bsl\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"task\": [],\n",
    "    \"algorithm\":  [],\n",
    "    \"min_ess\": [],\n",
    "    \"mean_ess\": [],\n",
    "    \"max_ess\": [],\n",
    "    \"c2st_all\": [],\n",
    "    \"c2st_thinned\": []\n",
    "}\n",
    "\n",
    "for task_name in task_names:\n",
    "    for algoritm_name in algorithm_names:\n",
    "        print(f\"{task_name}: {algoritm_name}\")\n",
    "        posterior_samples = torch.tensor(np.genfromtxt(f\"./samples/{task_name}_{algoritm_name}.txt\"))\n",
    "        task = sbibm.get_task(task_name)\n",
    "        reference_samples = task.get_reference_posterior_samples(num_observation=1)\n",
    "        \n",
    "        ess = tfp.mcmc.effective_sample_size(posterior_samples)\n",
    "\n",
    "        X = posterior_samples\n",
    "        Y = reference_samples[1:X.shape[0], :]\n",
    "        c2st_all = c2st(X, Y)\n",
    "        \n",
    "        X = thin(posterior_samples, 300)\n",
    "        Y = reference_samples[1:X.shape[0], :]\n",
    "        c2st_thinned = c2st(X, Y)        \n",
    "        \n",
    "        metrics[\"task\"].append(task_name)\n",
    "        metrics[\"algorithm\"].append(algoritm_name)\n",
    "        metrics[\"min_ess\"].append(np.min(ess))\n",
    "        metrics[\"mean_ess\"].append(np.mean(ess))\n",
    "        metrics[\"max_ess\"].append(np.max(ess))\n",
    "        metrics[\"c2st_all\"].append(c2st_all)\n",
    "        metrics[\"c2st_thinned\"].append(c2st_thinned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec166636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Dataframe(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results/metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
